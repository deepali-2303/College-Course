{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGdLAuRicY_d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import graphviz\n",
        "import pydotplus\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWU5Nk64ce7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(target_col):\n",
        "  elements, counts = np.unique(target_col, return_counts=True)\n",
        "  entropy = -np.sum([(counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
        "  return entropy"
      ],
      "metadata": {
        "id": "pAPp3e9hcmn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(entropy(data['Temperature']))\n",
        "print(entropy(data['Temperature']))\n",
        "print(entropy(data['Temperature']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNlMzyyrimEz",
        "outputId": "5c905a06-c8be-410a-9a9d-1f2f6d5395c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.584962500721156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def infoGain(data, split_attribute_name, target_name=\"class\"):\n",
        "    total_entropy = entropy(data[target_name])\n",
        "    vals, counts= np.unique(data[split_attribute_name], return_counts=True)\n",
        "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain"
      ],
      "metadata": {
        "id": "rIcnto52dyiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(infoGain(data,'Temperature','Temperature'))\n",
        "print(infoGain(data,'Wind','Wind'))\n",
        "print(infoGain(data,'Humidity','Humidity'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyzwy9yOisA8",
        "outputId": "cc1a06b4-0435-4b8b-89c3-826a86954c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.584962500721156\n",
            "0.9182958340544896\n",
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split(data, originaldata, features, target_attribute_name=\"class\", parent_node_class=None):\n",
        "    if len(np.unique(data[target_attribute_name])) <= 1:\n",
        "        return np.unique(data[target_attribute_name])[0]\n",
        "    elif len(data) == 0:\n",
        "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name], return_counts=True)[1])]\n",
        "    elif len(features) == 0:\n",
        "        return parent_node_class\n",
        "    else:\n",
        "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name], return_counts=True)[1])]\n",
        "        item_values = [infoGain(data, feature, target_attribute_name) for feature in features]\n",
        "        best_feature_index = np.argmax(item_values)\n",
        "        best_feature = features[best_feature_index]\n",
        "        tree = {best_feature: {}}\n",
        "        features = [i for i in features if i != best_feature]\n",
        "        for value in np.unique(data[best_feature]):\n",
        "            value = value\n",
        "            sub_data = data.where(data[best_feature] == value).dropna()\n",
        "            subtree = split(sub_data, originaldata, features, target_attribute_name, parent_node_class)\n",
        "            tree[best_feature][value] = subtree\n",
        "        return tree"
      ],
      "metadata": {
        "id": "Svvhlyr6gXWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(query, tree, default=1):\n",
        "    for key in list(query.keys()):\n",
        "        if key in list(tree.keys()):\n",
        "            try:\n",
        "                result = tree[key][query[key]]\n",
        "            except:\n",
        "                return default\n",
        "            result = tree[key][query[key]]\n",
        "            if isinstance(result, dict):\n",
        "                return predict(query, result)\n",
        "            else:\n",
        "                return result\n"
      ],
      "metadata": {
        "id": "UYC40DpVdygH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "features = data.columns[:-1].tolist()\n",
        "target = data.columns[-1]\n",
        "tree = split(data, data, features, target)\n",
        "\n",
        "# Test data\n",
        "queries = pd.DataFrame([\n",
        "    ['Hot', 'High', 'Weak'],\n",
        "    ['Mild', 'Normal', 'Strong'],\n",
        "    ['Cool','Normal', 'Weak']\n",
        "], columns=['Temperature', 'Humidity', 'Wind'])\n",
        "\n",
        "predictions = []\n",
        "for i in range(len(queries)):\n",
        "    predictions.append(predict(queries.iloc[i], tree, 1))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "def print_tree(tree, dot_object=None, parent_node=None, edge_label=''):\n",
        "    if dot_object is None:\n",
        "        dot_object = graphviz.Digraph()\n",
        "        dot_object.node(name=str(tree))\n",
        "    elif not isinstance(tree, dict):\n",
        "        leaf_node = str(tree)\n",
        "        dot_object.node(name=leaf_node)\n",
        "        dot_object.edge(parent_node, leaf_node, label=edge_label)\n",
        "    else:\n",
        "        for node, subtree in tree.items():\n",
        "            if parent_node is not None:\n",
        "                dot_object.edge(parent_node, node, label=edge_label)\n",
        "            if isinstance(subtree, dict):\n",
        "                for value, subsubtree in subtree.items():\n",
        "                    print_tree(subsubtree, dot_object, node, str(value))\n",
        "            else:\n",
        "                print_tree(subtree, dot_object, node, str(value))\n",
        "    return dot_object\n",
        "\n",
        "dot_object = print_tree(tree)\n",
        "dot_object.view()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ZepsbwgHdydf",
        "outputId": "df34438f-7c3f-4945-a18b-e9db84ee3ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No', 'No', 'Yes']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Digraph.gv.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UD2AG3Vjdya8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zazN6Y6odyYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_uMZd-7rdyVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7p7g4dopdyS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MujyrwI7dyQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqncdFhFdyMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OrXV_KKhiIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}